{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687e4423-0ae5-4cb5-9471-82e82e00e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e.\n",
      "üìÇ R√©sultats seront dans : /home/ulysse/Bureau/CD LAB/IRM/WORK/results\n",
      "‚öôÔ∏è Device : cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Les poids sont introuvables ici : /home/ulysse/Bureau/CD LAB/IRM/WORK/weights/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLe dossier SegDINO est introuvable ici : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEGDINO_REPO\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(WEIGHTS_PATH):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLes poids sont introuvables ici : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEIGHTS_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Les poids sont introuvables ici : /home/ulysse/Bureau/CD LAB/IRM/WORK/weights/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Barre de progression pour Jupyter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemins relatifs (supposant que le notebook est √† la racine du projet)\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Tes dossiers de donn√©es\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, \"data\", \"dataset_continuous_lesions\", \"image\")\n",
    "MASKS_DIR = os.path.join(BASE_DIR, \"data\", \"dataset_continuous_lesions\", \"mask\")\n",
    "\n",
    "\n",
    "# Tes dossiers de code et poids\n",
    "SEGDINO_REPO = os.path.join(BASE_DIR, \"SegDINO\")\n",
    "DINOV3_REPO = os.path.join(BASE_DIR, \"dinov3\")\n",
    "WEIGHTS_PATH = os.path.join(BASE_DIR, \"weights\", \"dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\")\n",
    "\n",
    "# Dossier de sortie (Tu le cr√©es toi-m√™me ici !)\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Param√®tres\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cuda')\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "LR = 2e-4\n",
    "\n",
    "print(f\"‚úÖ Configuration charg√©e.\")\n",
    "print(f\"üìÇ R√©sultats seront dans : {RESULTS_DIR}\")\n",
    "print(f\"‚öôÔ∏è Device : {DEVICE}\")\n",
    "\n",
    "# V√©rification rapide\n",
    "if not os.path.exists(SEGDINO_REPO):\n",
    "    raise FileNotFoundError(f\"Le dossier SegDINO est introuvable ici : {SEGDINO_REPO}\")\n",
    "if not os.path.exists(WEIGHTS_PATH):\n",
    "    raise FileNotFoundError(f\"Les poids sont introuvables ici : {WEIGHTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97eb162d-5430-4f17-8dfa-35a92f8cbf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset initialis√© : 687 s√©quences continues trouv√©es.\n",
      "   Exemple de cl√© : sub-strokecase0001_axial_seq01\n",
      "   Contient 2 images (profondeur).\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transformations (Standard pour DINO)\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "\n",
    "# === REMPLACE TA CELLULE DE DATASET PAR CELLE-CI ===\n",
    "\n",
    "class PatientVolumetricDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Dictionnaire pour regrouper les fichiers\n",
    "        # Cl√© = Patient_Axe_Sequence (ex: sub-strokecase0005_axial_seq02)\n",
    "        # Valeur = Liste des fichiers\n",
    "        self.volume_groups = {}\n",
    "        \n",
    "        all_files = sorted([f for f in os.listdir(img_dir) if f.endswith('.png')])\n",
    "        \n",
    "        # --- PARSING DU NOMMAGE SP√âCIFIQUE ---\n",
    "        # Format : sub-strokecase0005_axial_019_seq02_01.png\n",
    "        # parts[0] = sub-strokecase0005 (Patient)\n",
    "        # parts[1] = axial              (Axe)\n",
    "        # parts[2] = 019                (Slice Globale - on ignore pour le groupement)\n",
    "        # parts[3] = seq02              (ID S√©quence)\n",
    "        # parts[4] = 01.png             (Position locale)\n",
    "        \n",
    "        for f in all_files:\n",
    "            try:\n",
    "                parts = f.split('_')\n",
    "                if len(parts) >= 5:\n",
    "                    # On construit la cl√© unique pour ce bloc 3D\n",
    "                    # Cl√© = Patient + Axe + SeqID\n",
    "                    unique_group_key = f\"{parts[0]}_{parts[1]}_{parts[3]}\"\n",
    "                    \n",
    "                    if unique_group_key not in self.volume_groups:\n",
    "                        self.volume_groups[unique_group_key] = []\n",
    "                    self.volume_groups[unique_group_key].append(f)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur parsing fichier {f}: {e}\")\n",
    "                \n",
    "        self.group_ids = list(self.volume_groups.keys())\n",
    "        \n",
    "        # Stats pour v√©rifier\n",
    "        print(f\"‚úÖ Dataset initialis√© : {len(self.group_ids)} s√©quences continues trouv√©es.\")\n",
    "        if len(self.group_ids) > 0:\n",
    "            example_key = self.group_ids[0]\n",
    "            print(f\"   Exemple de cl√© : {example_key}\")\n",
    "            print(f\"   Contient {len(self.volume_groups[example_key])} images (profondeur).\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.group_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        group_key = self.group_ids[idx]\n",
    "        files = self.volume_groups[group_key]\n",
    "        \n",
    "        # TRI CRUCIAL : On doit trier les images pour qu'elles soient dans l'ordre (00, 01, 02...)\n",
    "        # On trie sur la toute fin du fichier : le num√©ro avant .png\n",
    "        # ex: ...seq02_01.png -> 1\n",
    "        files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "        \n",
    "        imgs = []\n",
    "        masks = []\n",
    "        \n",
    "        for f_name in files:\n",
    "            img_path = os.path.join(self.img_dir, f_name)\n",
    "            mask_path = os.path.join(self.mask_dir, f_name)\n",
    "            \n",
    "            # --- Image ---\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            imgs.append(img)\n",
    "            \n",
    "            # --- Masque ---\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            # Resize manuel en Nearest car les transforms sont souvent pour l'interpolation bilin√©aire\n",
    "            mask = mask.resize((224, 224), Image.NEAREST)\n",
    "            mask_np = np.array(mask)\n",
    "            mask_tensor = torch.from_numpy(mask_np > 0).float().unsqueeze(0)\n",
    "            masks.append(mask_tensor)\n",
    "        \n",
    "        # Stack pour cr√©er le volume\n",
    "        # (Depth, 3, H, W)\n",
    "        volume_img = torch.stack(imgs, dim=0)\n",
    "        # (Depth, 1, H, W)\n",
    "        volume_mask = torch.stack(masks, dim=0)\n",
    "        \n",
    "        return volume_img, volume_mask\n",
    "\n",
    "# Cr√©ation des Loaders (BATCH_SIZE DOIT √äTRE 1 ici pour g√©rer des profondeurs variables)\n",
    "full_ds = PatientVolumetricDataset(IMAGES_DIR, MASKS_DIR, transform=img_transforms)\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "val_size = len(full_ds) - train_size\n",
    "train_ds, val_ds = random_split(full_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Important : batch_size=1\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6768f303-191b-4b85-bb68-ad8eb8fd227d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe DPT import√©e avec succ√®s.\n",
      "üèóÔ∏è Chargement du backbone DINOv3 depuis : /home/maxime/Documents/CD Lab/IRM/SegDinov3/dinov3\n",
      "üíâ Poids : /home/maxime/Documents/CD Lab/IRM/SegDinov3/weights/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Backbone DINOv3 charg√©.\n",
      "‚úÖ Mod√®le complet (DPT + Backbone) pr√™t sur GPU/CPU.\n"
     ]
    }
   ],
   "source": [
    "# 1. Ajout du repo SegDINO au Path Python (pour trouver dpt.py et blocks.py)\n",
    "if SEGDINO_REPO not in sys.path: sys.path.append(SEGDINO_REPO)\n",
    "\n",
    "# 2. Importation de la classe DPT (c'est le vrai nom du mod√®le !)\n",
    "try:\n",
    "    from dpt import DPT\n",
    "    print(\"‚úÖ Classe DPT import√©e avec succ√®s.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erreur d'import : {e}\")\n",
    "    print(f\"V√©rifiez que le dossier {SEGDINO_REPO} contient bien dpt.py\")\n",
    "    raise e\n",
    "\n",
    "# 3. Chargement du Backbone DINOv3 via torch.hub en LOCAL\n",
    "# C'est la m√©thode utilis√©e dans train_segdino.py\n",
    "print(f\"üèóÔ∏è Chargement du backbone DINOv3 depuis : {DINOV3_REPO}\")\n",
    "print(f\"üíâ Poids : {WEIGHTS_PATH}\")\n",
    "\n",
    "try:\n",
    "    # On charge le mod√®le 'small' (vits16)\n",
    "    # source='local' force √† utiliser le dossier dinov3 clon√© au lieu d'internet\n",
    "    backbone = torch.hub.load(\n",
    "        repo_or_dir=DINOV3_REPO, \n",
    "        model='dinov3_vitl16', \n",
    "        source='local', \n",
    "        weights=WEIGHTS_PATH\n",
    "    )\n",
    "    print(\"‚úÖ Backbone DINOv3 charg√©.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur torch.hub : {e}\")\n",
    "    print(\"V√©rifiez que le dossier 'dinov3' est bien le clone du repo facebookresearch/dinov3\")\n",
    "    raise e\n",
    "\n",
    "# 4. Instanciation du mod√®le complet\n",
    "# On passe le backbone charg√© √† la classe DPT\n",
    "# nclass=1 car on fait de la segmentation binaire (L√©sion vs Fond)\n",
    "try:\n",
    "    model = DPT(nclass=1, backbone=backbone)\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"‚úÖ Mod√®le complet (DPT + Backbone) pr√™t sur GPU/CPU.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur instanciation DPT : {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5173de1-4625-4ec3-a603-ab1d4fcc24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: logits (sortie du mod√®le)\n",
    "        # targets: labels (0 ou 1)\n",
    "        \n",
    "        # Sigmoid pour avoir des probas entre 0 et 1\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        \n",
    "        # Aplatir les dimensions (Batch, Depth, H, W -> Vecteur)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        # On veut maximiser le Dice, donc minimiser (1 - Dice)\n",
    "        return 1 - dice\n",
    "\n",
    "# On combine BCE et Dice pour la stabilit√©\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        return 0.5 * self.bce(inputs, targets) + 0.5 * self.dice(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c326a77-9192-4b32-ae46-1a3f2e762b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDINO_3D_Wrapper(nn.Module):\n",
    "    def __init__(self, model_2d):\n",
    "        super().__init__()\n",
    "        self.model_2d = model_2d\n",
    "        \n",
    "        # On d√©bloque les gradients 2D (sera g√©r√© par l'optimiseur)\n",
    "        for param in self.model_2d.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        # --- CORRECTION ICI : InstanceNorm3d au lieu de BatchNorm3d ---\n",
    "        # C'est beaucoup plus stable quand batch_size = 1\n",
    "        self.refinement_3d = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm3d(16),  # <--- CHANGEMENT CRITIQUE\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm3d(16),  # <--- CHANGEMENT CRITIQUE\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(16, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        # Init √† z√©ro pour connexion r√©siduelle douce\n",
    "        nn.init.zeros_(self.refinement_3d[-1].weight)\n",
    "        nn.init.zeros_(self.refinement_3d[-1].bias)\n",
    "\n",
    "    def forward(self, volume_img):\n",
    "        b, depth, c, h, w = volume_img.shape\n",
    "        \n",
    "        # 1. Passage 2D\n",
    "        img_flat = volume_img.view(b * depth, c, h, w)\n",
    "        out = self.model_2d(img_flat)\n",
    "        \n",
    "        if isinstance(out, dict): pred_2d = out['pred']\n",
    "        elif isinstance(out, (list, tuple)): pred_2d = out[0]\n",
    "        else: pred_2d = out\n",
    "            \n",
    "        # 2. Reshape 3D\n",
    "        x_3d_input = pred_2d.view(b, depth, 1, h, w).permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # 3. Passage 3D R√©siduel\n",
    "        residual = self.refinement_3d(x_3d_input)\n",
    "        \n",
    "        # Connexion r√©siduelle : Le 3D corrige le 2D\n",
    "        output = x_3d_input + residual\n",
    "        \n",
    "        return output.permute(0, 2, 1, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e399bd-b13a-418f-b447-f51163d3da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOSS PLUS DOUCE ---\n",
    "class WeightedCombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_bce=20.0): # On r√©duit √† 20 (suffisant pour le d√©s√©quilibre)\n",
    "        super(WeightedCombinedLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weight_bce]).to(DEVICE))\n",
    "        self.dice_loss = DiceLoss(smooth=1.0)\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        return 0.5 * self.bce(inputs, targets) + 0.5 * self.dice_loss(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe3e09-77ff-43a7-ae44-bc191bd8bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_score(logits, targets, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Calcule le Dice Score pour un volume ou une image.\n",
    "    logits : Sortie brute du r√©seau (avant Sigmoid)\n",
    "    targets : Masque binaire r√©el (0 ou 1)\n",
    "    smooth : Petit nombre pour √©viter la division par 0 si tout est noir\n",
    "    \"\"\"\n",
    "    # 1. On applique Sigmoid pour avoir des probabilit√©s entre 0 et 1\n",
    "    probs = torch.sigmoid(logits)\n",
    "    \n",
    "    # 2. On seuille √† 0.5 pour avoir du binaire (0 ou 1)\n",
    "    preds = (probs > 0.5).float()\n",
    "    \n",
    "    # 3. Aplatir les tenseurs (transformer le volume 3D en une longue ligne)\n",
    "    # Cela permet de calculer l'intersection facilement peu importe les dimensions\n",
    "    preds_flat = preds.view(-1)\n",
    "    targets_flat = targets.view(-1)\n",
    "    \n",
    "    # 4. Calcul de l'intersection et de l'union\n",
    "    intersection = (preds_flat * targets_flat).sum()\n",
    "    union = preds_flat.sum() + targets_flat.sum()\n",
    "    \n",
    "    # 5. Formule du Dice : 2 * Intersection / (Total pixels pr√©dits + Total pixels r√©els)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return dice.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b692923-94ce-467b-9e45-4e5fb94ca865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17507/914668173.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©marrage Entra√Ænement Final (Mode Stable)\n",
      "   Note: Le Dice va commencer bas et monter progressivement.\n",
      "üöÄ D√©marrage Entra√Ænement Final (Mode AMP - √âconomie M√©moire)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|                                       | 0/600 [00:00<?, ?it/s]/tmp/ipykernel_17507/914668173.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:19<00:00,  1.88it/s, loss=0.382, dice=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 1 | Train Dice: 0.3044 | Val Dice: 0.4131\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:06<00:00,  1.96it/s, loss=3.815, dice=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 2 | Train Dice: 0.4415 | Val Dice: 0.4762\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:06<00:00,  1.96it/s, loss=0.455, dice=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 3 | Train Dice: 0.4797 | Val Dice: 0.4962\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:13<00:00,  1.91it/s, loss=0.448, dice=0.160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 4 | Train Dice: 0.5020 | Val Dice: 0.5233\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:06<00:00,  1.96it/s, loss=0.503, dice=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 5 | Train Dice: 0.5226 | Val Dice: 0.5287\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:18<00:00,  1.89it/s, loss=0.367, dice=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 6 | Train Dice: 0.5406 | Val Dice: 0.5289\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:18<00:00,  1.89it/s, loss=0.436, dice=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 7 | Train Dice: 0.5546 | Val Dice: 0.5103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:17<00:00,  1.89it/s, loss=0.326, dice=0.409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 8 | Train Dice: 0.5672 | Val Dice: 0.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [05:22<00:00,  1.86it/s, loss=0.362, dice=0.423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 9 | Train Dice: 0.5727 | Val Dice: 0.5523\n",
      "   üíæ Mod√®le sauvegard√© (Nouveau record validation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|‚ñà‚ñà‚ñà‚ñà| 600/600 [05:20<00:00,  1.87it/s, loss=0.316, dice=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 10 | Train Dice: 0.5836 | Val Dice: 0.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30:  96%|‚ñà‚ñà‚ñà‚ñä| 578/600 [05:10<00:11,  1.86it/s, loss=0.489, dice=0.370]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Barre de progression pour Jupyter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Listes pour stocker l'historique (pour les graphiques plus tard)\n",
    "history = {'train_loss': [], 'train_dice': [], 'val_dice': []}\n",
    "best_val_dice = 0.0\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION FINALE ET STABLE\n",
    "# ==========================================\n",
    "\n",
    "# 1. R√©initialisation propre du mod√®le\n",
    "model_3d = SegDINO_3D_Wrapper(model).to(DEVICE)\n",
    "\n",
    "# 2. On g√®le le backbone DINO (trop lourd), on entra√Æne le reste\n",
    "for param in model_3d.model_2d.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. Optimiseur (LR ajust√© pour l'entra√Ænement complet)\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model_3d.parameters()), \n",
    "    lr=2e-4, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# 4. Loss Pond√©r√©e (Stable)\n",
    "criterion = WeightedCombinedLoss(weight_bce=10.0)\n",
    "\n",
    "# ==========================================\n",
    "# BOUCLE D'ENTRA√éNEMENT\n",
    "# ==========================================\n",
    "\n",
    "history = {'train_loss': [], 'train_dice': [], 'val_dice': []}\n",
    "best_val_dice = 0.0\n",
    "\n",
    "print(f\"üöÄ D√©marrage Entra√Ænement Final (Mode Stable)\")\n",
    "print(f\"   Note: Le Dice va commencer bas et monter progressivement.\")\n",
    "\n",
    "# Import pour le Mixed Precision\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 1. Cr√©ation du Scaler (avant la boucle)\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(f\"üöÄ D√©marrage Entra√Ænement Final (Mode AMP - √âconomie M√©moire)\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_3d.train()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for vol_img, vol_mask in pbar:\n",
    "        vol_img, vol_mask = vol_img.to(DEVICE), vol_mask.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- CHANGEMENT 1 : Context Autocast ---\n",
    "        # PyTorch g√®re auto le passage en float16 pour ce qui est compatible\n",
    "        with autocast():\n",
    "            outputs_3d = model_3d(vol_img)\n",
    "            loss = criterion(outputs_3d, vol_mask)\n",
    "        \n",
    "        # --- CHANGEMENT 2 : Backprop via Scaler ---\n",
    "        # Le scaler g√®re les gradients pour √©viter qu'ils ne soient trop petits (underflow)\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # On doit \"unscale\" avant de clipper les gradients\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model_3d.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # M√©nage imm√©diat (Optionnel mais aide si tu es limite)\n",
    "        # del vol_img, vol_mask, outputs_3d\n",
    "        # torch.cuda.empty_cache() \n",
    "        \n",
    "        # M√©triques (Attention, on repasse en float32 pour le calcul CPU)\n",
    "        dice = compute_dice_score(outputs_3d.detach().float(), vol_mask.float())\n",
    "        running_loss += loss.item()\n",
    "        running_dice += dice\n",
    "        \n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.3f}\", 'dice': f\"{dice:.3f}\"})\n",
    "        \n",
    "    # ... (Le reste de la validation est inchang√©, mets juste 'with autocast():' dans la validation aussi)\n",
    "        \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_train_dice = running_dice / len(train_loader)\n",
    "    \n",
    "    # --- VALIDATION ---\n",
    "    model_3d.eval()\n",
    "    val_dice_total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vol_img, vol_mask in val_loader:\n",
    "            vol_img, vol_mask = vol_img.to(DEVICE), vol_mask.to(DEVICE)\n",
    "            outputs_3d = model_3d(vol_img)\n",
    "            val_dice_total += compute_dice_score(outputs_3d, vol_mask)\n",
    "            \n",
    "    avg_val_dice = val_dice_total / len(val_loader)\n",
    "    \n",
    "    # --- LOGS & SAUVEGARDE ---\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['train_dice'].append(avg_train_dice)\n",
    "    history['val_dice'].append(avg_val_dice)\n",
    "    \n",
    "    print(f\"End Epoch {epoch+1} | Train Dice: {avg_train_dice:.4f} | Val Dice: {avg_val_dice:.4f}\")\n",
    "    \n",
    "    # Sauvegarde au moindre progr√®s sur la validation\n",
    "    if avg_val_dice > best_val_dice:\n",
    "        best_val_dice = avg_val_dice\n",
    "        torch.save(model_3d.state_dict(), os.path.join(RESULTS_DIR, \"best_segdino_3d.pth\"))\n",
    "        print(f\"   üíæ Mod√®le sauvegard√© (Nouveau record validation)\")\n",
    "\n",
    "print(\"üèÅ Termin√© !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a144d04-b565-41b0-9359-f60f8bcafab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. AFFICHAGE DES COURBES D'APPRENTISSAGE\n",
    "# ==========================================\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Courbe de Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', color='red', marker='o')\n",
    "plt.title('√âvolution de la Loss (Erreur)')\n",
    "plt.xlabel('√âpoques')\n",
    "plt.ylabel('BCE Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Courbe de Dice\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_dice'], label='Train Dice', color='blue', linestyle='--')\n",
    "plt.plot(history['val_dice'], label='Validation Dice', color='green', marker='o', linewidth=2)\n",
    "plt.title('√âvolution du Dice Score (Qualit√© Segmentation)')\n",
    "plt.xlabel('√âpoques')\n",
    "plt.ylabel('Dice Score (0 √† 1)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"learning_curves.png\"))\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 2. VISUALISATION DES PR√âDICTIONS 3D\n",
    "# ==========================================\n",
    "print(\"\\nüì∏ G√©n√©ration d'un exemple de validation...\")\n",
    "\n",
    "model_3d.eval()\n",
    "\n",
    "# On r√©cup√®re UN patient complet dans le loader de validation\n",
    "vol_img, vol_mask = next(iter(val_loader)) \n",
    "\n",
    "# Envoi sur GPU et Pr√©diction\n",
    "vol_img = vol_img.to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    logits_3d = model_3d(vol_img)\n",
    "    preds_3d = (torch.sigmoid(logits_3d) > 0.5).float()\n",
    "\n",
    "# --- PR√âPARATION POUR AFFICHAGE ---\n",
    "depth = vol_img.shape[1] # Dimension 1 est la profondeur\n",
    "\n",
    "# On choisit 3 slices r√©parties (ex: 25%, 50%, 75%)\n",
    "# On s'assure que les indices sont valides (min 0, max depth-1)\n",
    "slice_indices = [int(depth*0.25), int(depth*0.50), int(depth*0.75)]\n",
    "slice_indices = [min(i, depth-1) for i in slice_indices]\n",
    "\n",
    "fig, axes = plt.subplots(len(slice_indices), 3, figsize=(12, 4 * len(slice_indices)))\n",
    "plt.suptitle(f\"R√©sultats sur un patient (Profondeur totale: {depth} slices)\", fontsize=16)\n",
    "\n",
    "# Gestion du cas o√π il n'y a qu'une seule slice √† afficher (si depth est tr√®s petit)\n",
    "if len(slice_indices) == 1: axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "for i, slice_idx in enumerate(slice_indices):\n",
    "    # --- 1. Image IRM (Input) ---\n",
    "    # Shape: (Batch, Depth, Channels, H, W) -> On prend [0, slice_idx]\n",
    "    img_slice = vol_img[0, slice_idx].cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Denormalization pour affichage propre\n",
    "    img_min, img_max = img_slice.min(), img_slice.max()\n",
    "    if img_max > img_min:\n",
    "        img_slice = (img_slice - img_min) / (img_max - img_min)\n",
    "    \n",
    "    # --- 2. V√©rit√© Terrain ---\n",
    "    # Shape: (Batch, Depth, Channel, H, W) -> On prend [0, slice_idx, 0]\n",
    "    mask_slice = vol_mask[0, slice_idx, 0].cpu().numpy()\n",
    "    \n",
    "    # --- 3. Pr√©diction (CORRECTION ICI) ---\n",
    "    # Shape: (Batch, Depth, Channel, H, W) -> On prend [0, slice_idx, 0]\n",
    "    pred_slice = preds_3d[0, slice_idx, 0].cpu().numpy()\n",
    "    \n",
    "    # --- AFFICHAGE ---\n",
    "    # Colonne 1 : IRM\n",
    "    axes[i, 0].imshow(img_slice)\n",
    "    axes[i, 0].set_title(f\"Slice {slice_idx} - IRM\", fontsize=10)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Colonne 2 : Masque R√©el\n",
    "    axes[i, 1].imshow(mask_slice, cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Slice {slice_idx} - V√©rit√©\", fontsize=10)\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Colonne 3 : Pr√©diction\n",
    "    axes[i, 2].imshow(pred_slice, cmap='gray')\n",
    "    \n",
    "    # Petit calcul de Dice local pour le titre\n",
    "    inter = (pred_slice * mask_slice).sum()\n",
    "    dice_slice = (2. * inter) / (pred_slice.sum() + mask_slice.sum() + 1e-6)\n",
    "    \n",
    "    col = 'green' if dice_slice > 0.7 else 'red'\n",
    "    axes[i, 2].set_title(f\"Pred (Dice: {dice_slice:.2f})\", color=col, fontweight='bold', fontsize=10)\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e0b0c-431d-4f37-86e1-ab3e5d7225a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELLULE DE DEBUG ===\n",
    "print(\"üîç INSPECTION DES DONN√âES\")\n",
    "\n",
    "# On prend un batch (un patient)\n",
    "vol_img, vol_mask = next(iter(train_loader))\n",
    "\n",
    "print(f\"Format Image : {vol_img.shape}\")\n",
    "print(f\"Format Masque : {vol_mask.shape}\")\n",
    "\n",
    "# 1. V√©rifier les valeurs de l'image (doit √™tre ~ entre -2 et +2 apr√®s normalisation)\n",
    "print(f\"\\n--- IMAGE ---\")\n",
    "print(f\"Min: {vol_img.min():.4f}, Max: {vol_img.max():.4f}, Mean: {vol_img.mean():.4f}\")\n",
    "if vol_img.max() > 10 or vol_img.min() < -10:\n",
    "    print(\"‚ö†Ô∏è ALERTE : Les valeurs de l'image semblent anormales pour DINO (Normalisation ?)\")\n",
    "\n",
    "# 2. V√©rifier le Masque (DOIT √™tre 0.0 et 1.0 uniquement)\n",
    "print(f\"\\n--- MASQUE ---\")\n",
    "unique_vals = torch.unique(vol_mask)\n",
    "print(f\"Valeurs uniques dans le masque : {unique_vals}\")\n",
    "print(f\"Nombre de pixels l√©sion (1.0) : {vol_mask.sum().item()}\")\n",
    "\n",
    "if len(unique_vals) > 2:\n",
    "    print(\"‚ö†Ô∏è ALERTE : Le masque n'est pas binaire ! Il contient d'autres valeurs.\")\n",
    "if vol_mask.sum() == 0:\n",
    "    print(\"‚ö†Ô∏è ALERTE : Ce patient n'a AUCUNE l√©sion (masque vide). Le mod√®le ne peut rien apprendre ici.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e5b80-0ec3-4e50-b449-d9c816a99a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # Barre de progression pour Jupyter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"üß™ TEST D'OVERFITTING SUR UN SEUL PATIENT\")\n",
    "\n",
    "# On prend UN SEUL patient et on le fige\n",
    "single_img, single_mask = next(iter(train_loader))\n",
    "single_img, single_mask = single_img.to(DEVICE), single_mask.to(DEVICE)\n",
    "\n",
    "'''\n",
    "# On r√©initialise un petit mod√®le pour le test\n",
    "test_optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model_3d.parameters()), lr=1e-3)\n",
    "test_criterion = CombinedLoss() # Ta loss actuelle\n",
    "'''\n",
    "\n",
    "# R√©instancie le mod√®le (pour effacer l'historique du crash)\n",
    "model_3d = SegDINO_3D_Wrapper(model).to(DEVICE)\n",
    "\n",
    "# On g√®le le backbone DINO\n",
    "for param in model_3d.model_2d.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Learning Rate un peu plus doux\n",
    "test_optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model_3d.parameters()), \n",
    "    lr=1e-4, \n",
    "    weight_decay=0 # Pas de decay pour le test d'overfitting\n",
    ")\n",
    "\n",
    "# Loss pond√©r√©e mod√©r√©e\n",
    "test_criterion = WeightedCombinedLoss(weight_bce=10.0) # 10 au lieu de 20 ou 100\n",
    "\n",
    "model_3d.train()\n",
    "\n",
    "pbar = tqdm(range(50), desc=\"Overfitting Test\")\n",
    "losses = []\n",
    "dices = []\n",
    "\n",
    "for i in pbar:\n",
    "    test_optimizer.zero_grad()\n",
    "    \n",
    "    output = model_3d(single_img)\n",
    "    loss = test_criterion(output, single_mask)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model_3d.parameters(), max_norm=1.0)\n",
    "    test_optimizer.step()\n",
    "    \n",
    "    # Dice\n",
    "    dice = compute_dice_score(output.detach(), single_mask)\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    dices.append(dice)\n",
    "    pbar.set_postfix({'loss': loss.item(), 'dice': dice})\n",
    "\n",
    "# Affichage r√©sultat\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dices)\n",
    "plt.title(\"Dice Score sur 1 patient (Doit atteindre ~1.0)\")\n",
    "plt.show()\n",
    "\n",
    "if dices[-1] > 0.8:\n",
    "    print(\"‚úÖ LE MOD√àLE FONCTIONNE ! Il est capable d'apprendre.\")\n",
    "    print(\"   -> Le probl√®me vient donc de la difficult√© des donn√©es ou de la vari√©t√©.\")\n",
    "else:\n",
    "    print(\"‚ùå ECHEC : Le mod√®le n'arrive m√™me pas √† apprendre par c≈ìur 1 image.\")\n",
    "    print(\"   -> Probl√®me d'architecture, de Loss, ou de Learning Rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30772b-754c-4070-a901-74eb5f97357c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DINOV3)",
   "language": "python",
   "name": "dinov3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
